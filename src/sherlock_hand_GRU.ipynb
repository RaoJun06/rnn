{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Recurrent Neural Network Trained on Sherlock Holmes\n",
    "\n",
    "*Patrick Coady (pcoady@alum.mit.edu)*\n",
    "\n",
    "This notebook trains a Recurrent Neural Network (RNN) on 3 *Sherlock Holmes* books. We use words as the input to the RNN (as opposed to a sequence of characters) and predict the last word in a sequence. A sampled loss function is used to avoid evaluating an ~11,500-way (i.e. vocabulary size) softmax on each training example.\n",
    "\n",
    "This notebook takes full advantage of [TensorBoard](https://www.tensorflow.org/get_started/embedding_viz):\n",
    "- view graph connections\n",
    "- monitor training loss\n",
    "- visualize weight and bias trajectories\n",
    "- visualize activations during training\n",
    "- Interactively explore 3D word embedding (t-SNE or PCA)\n",
    "\n",
    "Objectives:\n",
    "1. Learn Tensorboard\n",
    "2. Subjectively evaluate the quality of RNN-learned word-embeddings\n",
    "3. Compare Basic RNN, GRU and LSTM cells\n",
    "4. Build good example to help others learn TensorFlow and TensorBoard\n",
    "\n",
    "The results are are discussed in [this blog post](https://pat-coady.github.io/projects/2017/03/09/rnn-and-tensorboard.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tqdm import tqdm_notebook  # progress bar\n",
    "import time\n",
    "\n",
    "import docload  # convenient methods for loading and processing Project Gutenberg books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded and processed: 24080 lines, 247812 words.\n"
     ]
    }
   ],
   "source": [
    "# Load and process data\n",
    "files = ['../data/adventures_of_sherlock_holmes.txt',\n",
    "        '../data/hound_of_the_baskervilles.txt',\n",
    "        '../data/sign_of_the_four.txt']\n",
    "word_array, dictionary, num_lines, num_words = docload.build_word_array(\n",
    "    files, vocab_size=50000, gutenberg=True)\n",
    "reverse_dict = {v: k for k, v in dictionary.items()}\n",
    "print('Document loaded and processed: {} lines, {} words.'\n",
    "      .format(num_lines, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters and training configuration\n",
    "class Config(object):\n",
    "    \"\"\"Model parameters\"\"\"\n",
    "    def __init__(self, num_words):\n",
    "        self.vocab_size = num_words\n",
    "        self.batch_size = 32\n",
    "        self.num_rnn_steps = 20  # unrolled length of RNN\n",
    "        self.embed_size = 64     # input embedding\n",
    "        self.rnn_size = 128      # number of RNN units\n",
    "        self.hidden_size = 196   # hidden layer connected to last output of RNN\n",
    "        self.rui_init = 0.01     # maxval, -minval for random_uniform_initializer\n",
    "        self.vsi_init = 0.01     # stddev multiplier (factor) for variance_scaling_initializer\n",
    "        self.neg_samples = 64    # for noise contrastive estimation (candidate sampling loss function)\n",
    "        self.learn_rate = 0.05\n",
    "        self.momentum = 0.8\n",
    "        self.epochs = 2\n",
    "        self.embed_vis_depth = 2048  # number of word embeddings to visualize in TensorBoard\n",
    "\n",
    "config = Config(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Aliases for especially long TensorFlow calls\n",
    "rui = tf.random_uniform_initializer\n",
    "vsi = tf.contrib.layers.variance_scaling_initializer\n",
    "# Commonly used weight and bias initializers\n",
    "rui_initializer = rui(-config.rui_init, config.rui_init, dtype=tf.float32)\n",
    "vsi_initializer = vsi(factor=config.vsi_init, dtype=tf.float32)\n",
    "zero_initializer = tf.zeros_initializer(dtype=tf.float32)\n",
    "one_initializer = tf.ones_initializer(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def feeder(config, word_array):\n",
    "    \"\"\"Generator. Yields training example tuples: (input, target).\n",
    "\n",
    "    Args:\n",
    "        config: Config object with model parameters.\n",
    "        word_array: np.array (int), as generated by docload.build_word_array()\n",
    "\n",
    "    Returns:\n",
    "        Yields a tuple of NumPy arrays: (input, target)\n",
    "    \"\"\"\n",
    "    batch_width = len(word_array) // config.batch_size\n",
    "    # reshape data for easy slicing into shape = (batch_size, num_rnn_steps)\n",
    "    data = np.reshape(word_array[0 : config.batch_size*batch_width],\n",
    "                      (config.batch_size, batch_width))\n",
    "    shuffle_index = [x for x in range(batch_width - config.num_rnn_steps - 1)]\n",
    "    random.shuffle(shuffle_index)\n",
    "    for i in shuffle_index:\n",
    "        x = data[:, (i):(i+config.num_rnn_steps)]\n",
    "        y = data[:, i+config.num_rnn_steps].reshape((-1, 1))\n",
    "        yield (x, y)\n",
    "        \n",
    "def epoch_len(config, word_array):\n",
    "    \"\"\"Number of training steps in an epoch. Used for progress bar\"\"\"\n",
    "    batch_width = len(word_array) // config.batch_size\n",
    "    return batch_width - config.num_rnn_steps - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_rnn_cell(x, num_cells, batch_size):\n",
    "    \"\"\"Set up variables for re-use\"\"\"\n",
    "    i_sz = x.shape[1]+num_cells\n",
    "    o_sz = num_cells\n",
    "    with tf.variable_scope('GRU'):\n",
    "        Wr = tf.get_variable('Wr', (i_sz, o_sz), tf.float32, vsi_initializer)\n",
    "        Wz = tf.get_variable('Wz', (i_sz, o_sz), tf.float32, vsi_initializer)\n",
    "        W = tf.get_variable('W', (i_sz, o_sz), tf.float32, vsi_initializer)\n",
    "        br = tf.get_variable('br', o_sz, tf.float32, one_initializer)\n",
    "        bz = tf.get_variable('bz', o_sz, tf.float32, one_initializer)\n",
    "        b = tf.get_variable('b', o_sz, tf.float32, zero_initializer)\n",
    "        h_init = tf.get_variable('h_init', (batch_size, o_sz), tf.float32, zero_initializer)\n",
    "    \n",
    "    return h_init\n",
    "\n",
    "def cell(x, h_1):\n",
    "    \"\"\"Hand-coded GRU\"\"\"\n",
    "    with tf.variable_scope('GRU', reuse=True):\n",
    "        Wr = tf.get_variable('Wr')\n",
    "        Wz = tf.get_variable('Wz')\n",
    "        W = tf.get_variable('W')\n",
    "        br = tf.get_variable('br')\n",
    "        bz = tf.get_variable('bz')\n",
    "        b = tf.get_variable('b')\n",
    "    \n",
    "    xh = tf.concat([x, h_1], axis=1)\n",
    "    r = tf.sigmoid(tf.matmul(xh, Wr) + br)     # Eq. 5\n",
    "    rh_1 = r * h_1\n",
    "    xrh_1 = tf.concat([x, rh_1], axis=1)\n",
    "    z = tf.sigmoid(tf.matmul(xh, Wz) + bz)     # Eq. 6\n",
    "    h_tild = tf.tanh(tf.matmul(xrh_1, W) + b)  # Eq. 8\n",
    "    h = z*h_1 + (1-z)*h_tild                   # Eq. 7\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(config):\n",
    "    '''Embedding layer, RNN and hidden layer'''\n",
    "    with tf.name_scope('embedding'):\n",
    "        x = tf.placeholder(tf.int32, shape=(config.batch_size, config.num_rnn_steps), name='input')\n",
    "        with tf.variable_scope('embedding', initializer=rui_initializer):\n",
    "            embed_w = tf.get_variable('w', [config.vocab_size, config.embed_size])\n",
    "        embed_out = tf.nn.embedding_lookup(embed_w, x, name='output')\n",
    "        tf.summary.histogram('embed_out', embed_out)  # for TensorBoard\n",
    "        # keep only top N=embed_vis_depth vectors for TensorBoard visualization:\n",
    "        top_embed = tf.Variable(tf.zeros([config.embed_vis_depth, config.embed_size],\n",
    "                                         dtype=tf.float32),\n",
    "                                name=\"top_n_embedding\")\n",
    "        assign_embed = top_embed.assign(embed_w[:config.embed_vis_depth, :])\n",
    "    \n",
    "    s = [init_rnn_cell(embed_out[:, 0, :], config.rnn_size, config.batch_size)]\n",
    "    for i in range(config.num_rnn_steps):\n",
    "        s_1 = s[-1]\n",
    "        s.append(cell(embed_out[:, i, :], s_1))\n",
    "        \n",
    "    with tf.name_scope('hidden'):\n",
    "        rnn_last_output = s[-1]\n",
    "        with tf.variable_scope('hidden'):\n",
    "            hid_w = tf.get_variable('w', (config.rnn_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            hid_b = tf.get_variable('b', config.hidden_size, initializer=zero_initializer)\n",
    "        hid_out = tf.nn.tanh(tf.matmul(rnn_last_output, hid_w) + hid_b)\n",
    "        tf.summary.histogram('hid_out', hid_out)  # for TensorBoard\n",
    "            \n",
    "    return hid_out, x, top_embed, assign_embed, embed_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loss(config, hid_out):\n",
    "    \"\"\"Loss Function: noise contrastive estimation on final output of RNN\"\"\"\n",
    "    with tf.name_scope('output'):\n",
    "        y = tf.placeholder(tf.int32, shape=(config.batch_size, 1))\n",
    "        with tf.variable_scope('output'):\n",
    "            w = tf.get_variable('w', (config.vocab_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            b = tf.get_variable('b', config.vocab_size, initializer=zero_initializer)\n",
    "        batch_loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(w, b, inputs=hid_out, labels=y,\n",
    "                           num_sampled=config.neg_samples,\n",
    "                           num_classes=config.vocab_size,\n",
    "                           num_true=1), name='batch_loss')\n",
    "        tf.summary.scalar('batch_loss', batch_loss)\n",
    "        # keep only top N=embed_vis_depth vectors for TensorBoard visualization:\n",
    "        top_embed = tf.Variable(tf.zeros([config.embed_vis_depth, config.hidden_size],\n",
    "                                         dtype=tf.float32),\n",
    "                                name=\"top_n_embedding\")\n",
    "        assign_embed = top_embed.assign(w[:config.embed_vis_depth, :])\n",
    "    \n",
    "    with tf.name_scope('predict'):\n",
    "        y_hat = tf.argmax(tf.matmul(hid_out, w, transpose_b=True) + b, axis=1)\n",
    "    \n",
    "    return y, batch_loss, y_hat, top_embed, assign_embed, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(config, batch_loss):\n",
    "    with tf.name_scope('optimize'):\n",
    "        step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        optimizer = tf.train.MomentumOptimizer(config.learn_rate, config.momentum)\n",
    "        train_op = optimizer.minimize(batch_loss, name='minimize_op', global_step=step)\n",
    "    \n",
    "    return train_op, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MyGraph(object):\n",
    "    def __init__(self, config):\n",
    "        self.hid_out, self.x, self.top_embed_in, self.assign_embed_in, self.embed_w = model(config)\n",
    "        self.y, self.batch_loss, self.y_hat, self.top_embed_out, self.assign_embed_out, self.w = \\\n",
    "            loss(config, self.hid_out)\n",
    "        self.train_op, self.step = train(config, self.batch_loss)\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        # Save histogram of all trainable variables for viewing in TensorBoard\n",
    "        [tf.summary.histogram(v.name.replace(':', '_'), v) for v in tf.trainable_variables()]\n",
    "        self.summ = tf.summary.merge_all()\n",
    "        self.saver = tf.train.Saver(max_to_keep=2)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def embed_vis(summary_writer, g):\n",
    "    \"\"\"Setup for Tensorboard embedding visualization\"\"\"\n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    # input embedding\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = g.top_embed_in.name  \n",
    "    embedding.metadata_path = 'embed_metadata.tsv'\n",
    "    # output embedding\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = g.top_embed_out.name\n",
    "    embedding.metadata_path = 'embed_metadata.tsv'\n",
    "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(summary_writer, config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_logfile_name(config):\n",
    "    \"\"\"Generate logfile name based on training configuration and model params\"\"\"\n",
    "    logfile_name = ('../tf_logs/st={}_es={}_rs={}_lr={}_e={}'.\n",
    "                    format(config.num_rnn_steps, \n",
    "                           config.embed_size, config.rnn_size,\n",
    "                           config.learn_rate, config.epochs))\n",
    "    \n",
    "    return logfile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Loss (20 batch average): 5.020166110992432\n",
      "Epoch #2 Loss (20 batch average): 4.3899149894714355\n",
      "--- 187.64367985725403 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "logfile_name = build_logfile_name(config)\n",
    "summary_interval = 250\n",
    "move_avg_len = 20  # number of batches to average loss over\n",
    "move_avg_loss = np.zeros(move_avg_len)\n",
    "with tf.Graph().as_default():\n",
    "    g = MyGraph(config)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(g.init)\n",
    "        writer = tf.summary.FileWriter(logfile_name+'/', tf.get_default_graph())\n",
    "        start_time = time.time()\n",
    "        for e in range(config.epochs):\n",
    "            for t in tqdm_notebook(feeder(config, word_array),\n",
    "                                   total=epoch_len(config, word_array),\n",
    "                                   desc='Epoch #{}'.format(e+1), leave=False,\n",
    "                                  mininterval=1):\n",
    "                feed = {g.x: t[0], g.y: t[1]}\n",
    "                [_, batch_loss, step] = sess.run([g.train_op, g.batch_loss, g.step],\n",
    "                                               feed_dict=feed)\n",
    "                move_avg_loss[step % move_avg_len] = batch_loss\n",
    "                if (step % summary_interval) == 0:\n",
    "                    sess.run([g.assign_embed_in, g.assign_embed_out])\n",
    "                    writer.add_summary(sess.run(g.summ, feed_dict=feed), step)\n",
    "            print('Epoch #{} Loss ({} batch average): {}'.\n",
    "                  format(e+1, move_avg_len, np.mean(move_avg_loss)))\n",
    "            last_saved = g.saver.save(sess, logfile_name, global_step=e)\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))            \n",
    "        embed_vis(writer, g)\n",
    "        writer.close()\n",
    "        \n",
    "# Write metadata file for TensorBoard embedding visualization\n",
    "with open('../tf_logs/embed_metadata.tsv', 'w') as f:\n",
    "    for i in range(config.embed_vis_depth):\n",
    "        f.write(reverse_dict[i]+'\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tqdm_notebook in module tqdm:\n",
      "\n",
      "tqdm_notebook(*args, **kwargs)\n",
      "    See tqdm._tqdm_notebook.tqdm_notebook for full documentation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tqdm_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class tqdm_notebook in module tqdm._tqdm_notebook:\n",
      "\n",
      "class tqdm_notebook(tqdm._tqdm.tqdm)\n",
      " |  Experimental IPython/Jupyter Notebook widget using tqdm!\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      tqdm_notebook\n",
      " |      tqdm._tqdm.tqdm\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      iterable  : iterable, optional\n",
      " |          Iterable to decorate with a progressbar.\n",
      " |          Leave blank to manually manage the updates.\n",
      " |      desc  : str, optional\n",
      " |          Prefix for the progressbar.\n",
      " |      total  : int, optional\n",
      " |          The number of expected iterations. If unspecified,\n",
      " |          len(iterable) is used if possible. As a last resort, only basic\n",
      " |          progress statistics are displayed (no ETA, no progressbar).\n",
      " |          If `gui` is True and this parameter needs subsequent updating,\n",
      " |          specify an initial arbitrary large positive integer,\n",
      " |          e.g. int(9e9).\n",
      " |      leave  : bool, optional\n",
      " |          If [default: True], keeps all traces of the progressbar\n",
      " |          upon termination of iteration.\n",
      " |      file  : `io.TextIOWrapper` or `io.StringIO`, optional\n",
      " |          Specifies where to output the progress messages\n",
      " |          [default: sys.stderr]. Uses `file.write(str)` and `file.flush()`\n",
      " |          methods.\n",
      " |      ncols  : int, optional\n",
      " |          The width of the entire output message. If specified,\n",
      " |          dynamically resizes the progressbar to stay within this bound.\n",
      " |          If unspecified, attempts to use environment width. The\n",
      " |          fallback is a meter width of 10 and no limit for the counter and\n",
      " |          statistics. If 0, will not print any meter (only stats).\n",
      " |      mininterval  : float, optional\n",
      " |          Minimum progress display update interval, in seconds [default: 0.1].\n",
      " |      maxinterval  : float, optional\n",
      " |          Maximum progress display update interval, in seconds [default: 10].\n",
      " |          Automatically adjusts `miniters` to correspond to `mininterval`\n",
      " |          after long display update lag. Only works if `dynamic_miniters`\n",
      " |          or monitor thread is enabled.\n",
      " |      miniters  : int, optional\n",
      " |          Minimum progress display update interval, in iterations.\n",
      " |          If 0 and `dynamic_miniters`, will automatically adjust to equal\n",
      " |          `mininterval` (more CPU efficient, good for tight loops).\n",
      " |          If > 0, will skip display of specified number of iterations.\n",
      " |          Tweak this and `mininterval` to get very efficient loops.\n",
      " |          If your progress is erratic with both fast and slow iterations\n",
      " |          (network, skipping items, etc) you should set miniters=1.\n",
      " |      ascii  : bool, optional\n",
      " |          If unspecified or False, use unicode (smooth blocks) to fill\n",
      " |          the meter. The fallback is to use ASCII characters `1-9 #`.\n",
      " |      disable  : bool or None, optional\n",
      " |          Whether to disable the entire progressbar wrapper\n",
      " |          [default: False]. If set to None, disable on non-TTY.\n",
      " |      unit  : str, optional\n",
      " |          String that will be used to define the unit of each iteration\n",
      " |          [default: it].\n",
      " |      unit_scale  : bool, optional\n",
      " |          If set, the number of iterations will be reduced/scaled\n",
      " |          automatically and a metric prefix following the\n",
      " |          International System of Units standard will be added\n",
      " |          (kilo, mega, etc.) [default: False].\n",
      " |      dynamic_ncols  : bool, optional\n",
      " |          If set, constantly alters `ncols` to the environment (allowing\n",
      " |          for window resizes) [default: False].\n",
      " |      smoothing  : float, optional\n",
      " |          Exponential moving average smoothing factor for speed estimates\n",
      " |          (ignored in GUI mode). Ranges from 0 (average speed) to 1\n",
      " |          (current/instantaneous speed) [default: 0.3].\n",
      " |      bar_format  : str, optional\n",
      " |          Specify a custom bar string formatting. May impact performance.\n",
      " |          If unspecified, will use '{l_bar}{bar}{r_bar}', where l_bar is\n",
      " |          '{desc}{percentage:3.0f}%|' and r_bar is\n",
      " |          '| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'\n",
      " |          Possible vars: bar, n, n_fmt, total, total_fmt, percentage,\n",
      " |          rate, rate_fmt, elapsed, remaining, l_bar, r_bar, desc.\n",
      " |      initial  : int, optional\n",
      " |          The initial counter value. Useful when restarting a progress\n",
      " |          bar [default: 0].\n",
      " |      position  : int, optional\n",
      " |          Specify the line offset to print this bar (starting from 0)\n",
      " |          Automatic if unspecified.\n",
      " |          Useful to manage multiple bars at once (eg, from threads).\n",
      " |      postfix  : dict, optional\n",
      " |          Specify additional stats to display at the end of the bar.\n",
      " |      gui  : bool, optional\n",
      " |          WARNING: internal parameter - do not use.\n",
      " |          Use tqdm_gui(...) instead. If set, will attempt to use\n",
      " |          matplotlib animations for a graphical output [default: False].\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : decorated iterator.\n",
      " |  \n",
      " |  __iter__(self, *args, **kwargs)\n",
      " |      Backward-compatibility to use: for x in tqdm(iterable)\n",
      " |  \n",
      " |  close(self, *args, **kwargs)\n",
      " |      Cleanup and (if leave=False) close the progressbar.\n",
      " |  \n",
      " |  moveto(self, *args, **kwargs)\n",
      " |  \n",
      " |  update(self, *args, **kwargs)\n",
      " |      Manually update the progress bar, useful for streams\n",
      " |      such as reading files.\n",
      " |      E.g.:\n",
      " |      >>> t = tqdm(total=filesize) # Initialise\n",
      " |      >>> for current_buffer in stream:\n",
      " |      ...    ...\n",
      " |      ...    t.update(len(current_buffer))\n",
      " |      >>> t.close()\n",
      " |      The last line is highly recommended, but possibly not necessary if\n",
      " |      `t.update()` will be called in such a way that `filesize` will be\n",
      " |      exactly reached and printed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n  : int\n",
      " |          Increment to add to the internal counter of iterations\n",
      " |          [default: 1].\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  write(s, file=<ipykernel.iostream.OutStream object at 0x7fa104c19d68>, end='\\n') from builtins.type\n",
      " |      Print a message via tqdm_notebook (just an alias for print)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  status_printer(_, total=None, desc=None)\n",
      " |      Manage the printing of an IPython/Jupyter Notebook progress bar widget.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  monitor = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tqdm._tqdm.tqdm:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __exit__(self, *exc)\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  clear(self, nomove=False)\n",
      " |      Clear current bar display\n",
      " |  \n",
      " |  refresh(self)\n",
      " |      Force refresh the display of this bar\n",
      " |  \n",
      " |  set_description(self, desc=None)\n",
      " |      Set/modify description of the progress bar.\n",
      " |  \n",
      " |  set_postfix(self, ordered_dict=None, **kwargs)\n",
      " |      Set/modify postfix (additional stats)\n",
      " |      with automatic formatting based on datatype.\n",
      " |  \n",
      " |  unpause(self)\n",
      " |      Restart tqdm timer from last print time.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tqdm._tqdm.tqdm:\n",
      " |  \n",
      " |  pandas(*targs, **tkwargs) from builtins.type\n",
      " |      Registers the given `tqdm` class with\n",
      " |          pandas.core.\n",
      " |          ( frame.DataFrame\n",
      " |          | series.Series\n",
      " |          | groupby.DataFrameGroupBy\n",
      " |          | groupby.SeriesGroupBy\n",
      " |          ).progress_apply\n",
      " |      \n",
      " |      A new instance will be create every time `progress_apply` is called,\n",
      " |      and each instance will automatically close() upon completion.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      targs, tkwargs  : arguments for the tqdm instance\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> from tqdm import tqdm, tqdm_gui\n",
      " |      >>>\n",
      " |      >>> df = pd.DataFrame(np.random.randint(0, 100, (100000, 6)))\n",
      " |      >>> tqdm.pandas(ncols=50)  # can use tqdm_gui, optional kwargs, etc\n",
      " |      >>> # Now you can use `progress_apply` instead of `apply`\n",
      " |      >>> df.groupby(0).progress_apply(lambda x: x**2)\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      https://stackoverflow.com/questions/18603270/\n",
      " |      progress-indicator-during-pandas-operations-python\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tqdm._tqdm.tqdm:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  format_interval(t)\n",
      " |      Formats a number of seconds as a clock time, [H:]MM:SS\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      t  : int\n",
      " |          Number of seconds.\n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : str\n",
      " |          [H:]MM:SS\n",
      " |  \n",
      " |  format_meter(n, total, elapsed, ncols=None, prefix='', ascii=False, unit='it', unit_scale=False, rate=None, bar_format=None, postfix=None)\n",
      " |      Return a string-based progress bar given some parameters\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n  : int\n",
      " |          Number of finished iterations.\n",
      " |      total  : int\n",
      " |          The expected total number of iterations. If meaningless (), only\n",
      " |          basic progress statistics are displayed (no ETA).\n",
      " |      elapsed  : float\n",
      " |          Number of seconds passed since start.\n",
      " |      ncols  : int, optional\n",
      " |          The width of the entire output message. If specified,\n",
      " |          dynamically resizes the progress meter to stay within this bound\n",
      " |          [default: None]. The fallback meter width is 10 for the progress\n",
      " |          bar + no limit for the iterations counter and statistics. If 0,\n",
      " |          will not print any meter (only stats).\n",
      " |      prefix  : str, optional\n",
      " |          Prefix message (included in total width) [default: ''].\n",
      " |      ascii  : bool, optional\n",
      " |          If not set, use unicode (smooth blocks) to fill the meter\n",
      " |          [default: False]. The fallback is to use ASCII characters\n",
      " |          (1-9 #).\n",
      " |      unit  : str, optional\n",
      " |          The iteration unit [default: 'it'].\n",
      " |      unit_scale  : bool, optional\n",
      " |          If set, the number of iterations will printed with an\n",
      " |          appropriate SI metric prefix (K = 10^3, M = 10^6, etc.)\n",
      " |          [default: False].\n",
      " |      rate  : float, optional\n",
      " |          Manual override for iteration rate.\n",
      " |          If [default: None], uses n/elapsed.\n",
      " |      bar_format  : str, optional\n",
      " |          Specify a custom bar string formatting. May impact performance.\n",
      " |          [default: '{l_bar}{bar}{r_bar}'], where l_bar is\n",
      " |          '{desc}{percentage:3.0f}%|' and r_bar is\n",
      " |          '| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'\n",
      " |          Possible vars: bar, n, n_fmt, total, total_fmt, percentage,\n",
      " |          rate, rate_fmt, elapsed, remaining, l_bar, r_bar, desc.\n",
      " |      postfix  : str, optional\n",
      " |          Same as prefix but will be placed at the end as additional stats.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : Formatted meter and stats, ready to display.\n",
      " |  \n",
      " |  format_sizeof(num, suffix='')\n",
      " |      Formats a number (greater than unity) with SI Order of Magnitude\n",
      " |      prefixes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num  : float\n",
      " |          Number ( >= 1) to format.\n",
      " |      suffix  : str, optional\n",
      " |          Post-postfix [default: ''].\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : str\n",
      " |          Number with Order of Magnitude SI unit postfix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tqdm._tqdm.tqdm:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from tqdm._tqdm.tqdm:\n",
      " |  \n",
      " |  monitor_interval = 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tqdm._tqdm_notebook.tqdm_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "031e77f087c848c3bc37e0a6a77a6ba6": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "078f8f75ff3e48f3a86ab69ac8ffb3e1": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "25a8e6e6f1b044e986d97e4d99ee4226": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "297efc7fa75c4216959d2881bd776fbe": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "353079a6da814bfca4a846f2aee4395b": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "4641314ed3c84eccb6032e57d08e9200": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "4739b7b5a3ec4b0589efdaa9200eb0c8": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "75f5ec6b8c7e482c8f441c7d4db85cb2": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "87e1f0ae3396419da47cc1d6fdd50ba3": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "8985ac511432449da7f5bd79ad724295": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "9c9c08b931194cbc84fd5ecf40da7530": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a085cfa7abb441e3a41924e213f9ab95": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a4f73ccf73c24ea2bf3070203b02206a": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "b0fe3912730144078792e0e7cc4669e6": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "bc1fec7263134b6e85a92f7a9412950f": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "c3462b4fc7124ad5a4ec58264336184b": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "e0e2d33d9fef4d1d8fadf43bb987f055": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "ea575550969b45d19ca5648fa48bf037": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "ec9653beaa854419a23e3286f5e6e512": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "ede9f466f968476e9de4c2118636b32e": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
