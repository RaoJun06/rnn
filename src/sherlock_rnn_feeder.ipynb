{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "\n",
    "import docload  # convenient methods for loading and processing Project Gutenberg books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded and processed: 24080 lines, 247812 words.\n"
     ]
    }
   ],
   "source": [
    "# Load and process data\n",
    "files = ['../data/adventures_of_sherlock_holmes.txt',\n",
    "        '../data/hound_of_the_baskervilles.txt',\n",
    "        '../data/sign_of_the_four.txt']\n",
    "word_array, dictionary, num_lines, num_words = docload.build_word_array(\n",
    "    files, vocab_size=50000, gutenberg=True)\n",
    "reverse_dict = {v: k for k, v in dictionary.items()}\n",
    "print('Document loaded and processed: {} lines, {} words.'\n",
    "      .format(num_lines, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters and training configuration\n",
    "class Config(object):\n",
    "    \"\"\"Model parameters\"\"\"\n",
    "    def __init__(self, num_words):\n",
    "        self.vocab_size = num_words\n",
    "        self.batch_size = 32\n",
    "        self.num_rnn_steps = 20  # unrolled length of RNN\n",
    "        self.embed_size = 64     # input embedding\n",
    "        self.rnn_size = 128      # number of RNN units\n",
    "        self.hidden_size = 196   # hidden layer connected to last output of RNN\n",
    "        self.rui_init = 0.01     # maxval, -minval for random_uniform_initializer\n",
    "        self.vsi_init = 0.01     # stddev multiplier (factor) for variance_scaling_initializer\n",
    "        self.neg_samples = 64    # for noise contrastive estimation (candidate sampling loss function)\n",
    "        self.learn_rate = 0.05\n",
    "        self.momentum = 0.8\n",
    "        self.epochs = 1\n",
    "        self.embed_vis_depth = 2048  # number of word embeddings to visualize in TensorBoard\n",
    "\n",
    "config = Config(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Aliases for especially long TensorFlow calls\n",
    "rui = tf.random_uniform_initializer\n",
    "vsi = tf.contrib.layers.variance_scaling_initializer\n",
    "# Commonly used weight and bias initializers\n",
    "rui_initializer = rui(-config.rui_init, config.rui_init, dtype=tf.float32)\n",
    "vsi_initializer = vsi(factor=config.vsi_init, dtype=tf.float32)\n",
    "zero_initializer = tf.zeros_initializer(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(config, x):\n",
    "    '''Embedding layer, RNN and hidden layer'''\n",
    "    with tf.name_scope('embedding'):\n",
    "        with tf.variable_scope('embedding', initializer=rui_initializer):\n",
    "            embed_w = tf.get_variable('w', [config.vocab_size, config.embed_size])\n",
    "        embed_out = tf.nn.embedding_lookup(embed_w, x, name='output')\n",
    "            \n",
    "    with tf.variable_scope('rnn', initializer=vsi_initializer):\n",
    "        rnn_cell = tf.contrib.rnn.GRUCell(config.rnn_size, activation=tf.tanh)\n",
    "        rnn_out, state = tf.nn.dynamic_rnn(rnn_cell, embed_out, dtype=tf.float32)\n",
    "        \n",
    "    with tf.name_scope('hidden'):\n",
    "        rnn_last_output = rnn_out[:, config.num_rnn_steps-1, :]\n",
    "        with tf.variable_scope('hidden'):\n",
    "            hid_w = tf.get_variable('w', (config.rnn_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            hid_b = tf.get_variable('b', config.hidden_size, initializer=zero_initializer)\n",
    "        hid_out = tf.nn.tanh(tf.matmul(rnn_last_output, hid_w) + hid_b)\n",
    "            \n",
    "    return hid_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loss(config, hid_out, y):\n",
    "    \"\"\"Loss Function: noise contrastive estimation on final output of RNN\"\"\"\n",
    "    with tf.name_scope('output'):\n",
    "        with tf.variable_scope('output'):\n",
    "            w = tf.get_variable('w', (config.vocab_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            b = tf.get_variable('b', config.vocab_size, initializer=zero_initializer)\n",
    "        batch_loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(w, b, inputs=hid_out, labels=y,\n",
    "                           num_sampled=config.neg_samples,\n",
    "                           num_classes=config.vocab_size,\n",
    "                           num_true=1), name='batch_loss')\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(config, batch_loss):\n",
    "    with tf.name_scope('optimize'):\n",
    "        step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        optimizer = tf.train.MomentumOptimizer(config.learn_rate, config.momentum)\n",
    "        train_op = optimizer.minimize(batch_loss, name='minimize_op', global_step=step)\n",
    "    \n",
    "    return train_op, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MyGraph(object):\n",
    "    def __init__(self, config, word_array):\n",
    "        batch_width = len(word_array) // config.batch_size\n",
    "        self.data_initializer = tf.placeholder(dtype=tf.int32,\n",
    "                                    shape=(config.batch_size, batch_width))\n",
    "        self.data = tf.Variable(self.data_initializer, trainable=False, collections=[])\n",
    "        \n",
    "        i = tf.train.range_input_producer(batch_width - config.num_rnn_steps - 1, \n",
    "                                          num_epochs=config.epochs, shuffle=True).dequeue()\n",
    "        self.xq = self.data[:, (i):(i+config.num_rnn_steps)]\n",
    "        self.yq = tf.reshape(self.data[:, i+config.num_rnn_steps], (-1, 1))\n",
    "        \n",
    "        self.data_q = tf.FIFOQueue(20, dtypes = [tf.int32, tf.int32],\n",
    "                                  shapes=[(config.batch_size, config.num_rnn_steps),\n",
    "                                         (config.batch_size, 1)])\n",
    "        self.data_q_close = self.data_q.close()\n",
    "        self.enq_data = self.data_q.enqueue([self.xq, self.yq])\n",
    "        self.x, self.y = self.data_q.dequeue()\n",
    "\n",
    "        self.hid_out = model(config, self.x)\n",
    "        self.batch_loss = loss(config, self.hid_out, self.y)\n",
    "        self.train_op, self.step = train(config, self.batch_loss)\n",
    "        self.init = tf.group(tf.global_variables_initializer(),\n",
    "                            tf.local_variables_initializer())\n",
    "        self.saver = tf.train.Saver(max_to_keep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "move_avg_len = 20  # number of batches to average loss over\n",
    "move_avg_loss = np.zeros(move_avg_len)\n",
    "with tf.Graph().as_default():\n",
    "    g = MyGraph(config, word_array)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(g.init)\n",
    "        batch_width = len(word_array) // config.batch_size\n",
    "        # reshape data for easy slicing into shape = (batch_size, num_rnn_steps)\n",
    "        data = word_array[0 : config.batch_size*batch_width].reshape((config.batch_size, batch_width))\n",
    "        feeddict = {g.data_initializer: data}\n",
    "        sess.run(g.data.initializer, feed_dict = feeddict)\n",
    "        \n",
    "        q_runner = tf.train.QueueRunner(g.data_q, [g.enq_data], g.data_q_close)\n",
    "        tf.train.add_queue_runner(q_runner) \n",
    "        writer = tf.summary.FileWriter('../tf_logs/queue/', tf.get_default_graph())\n",
    "        coord = tf.train.Coordinator()\n",
    "        \n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            while not coord.should_stop():\n",
    "                [_, l, step] = sess.run([g.train_op, g.batch_loss, g.step])\n",
    "                move_avg_loss[step % move_avg_len] = l\n",
    "        except tf.errors.OutOfRangeError as e:\n",
    "            # Report exceptions to the coordinator.\n",
    "            coord.request_stop(e)\n",
    "        finally:\n",
    "            # Terminate as usual. It is safe to call `coord.request_stop()` twice.\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)            \n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        last_saved = g.saver.save(sess, '../tf_logs/queue', global_step=1)\n",
    "        writer.close()\n",
    "        \n",
    "print(np.mean(move_avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
