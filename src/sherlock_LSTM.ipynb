{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from wordvector import WordVector\n",
    "import docload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded and processed: 24080 lines, 244986 words.\n"
     ]
    }
   ],
   "source": [
    "files = ['../data/adventures_of_sherlock_holmes.txt',\n",
    "        '../data/hound_of_the_baskervilles.txt',\n",
    "        '../data/sign_of_the_four.txt']\n",
    "word_array, dictionary, num_lines, num_words = docload.build_word_array(\n",
    "    files, vocab_size=50000, gutenberg=True)\n",
    "\n",
    "print('Document loaded and processed: {} lines, {} words.'\n",
    "      .format(num_lines, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"Model parameters\"\"\"\n",
    "    def __init__(self, num_words):\n",
    "        self.vocab_size = num_words\n",
    "        self.batch_size = 32\n",
    "        self.num_rnn_steps = 10\n",
    "        self.embed_size = 128\n",
    "        self.rnn_size = 256\n",
    "        self.hidden_size = 128\n",
    "        self.rui_init = 0.01  # maxval, -minval for random_uniform_initializer\n",
    "        self.vsi_init = 0.01  # stddev multiplier (factor) for variance_scaling_initializer\n",
    "        self.neg_samples = 64  # for noise contrastive estimation (candidate sampling loss function)\n",
    "        self.learn_rate = 0.1\n",
    "        self.momentum = 0.9\n",
    "        self.epochs = 1000\n",
    "\n",
    "config = Config(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aliases for especially long TensorFlow calls\n",
    "rui = tf.random_uniform_initializer\n",
    "vsi = tf.contrib.layers.variance_scaling_initializer\n",
    "\n",
    "rui_initializer = rui(-config.rui_init, config.rui_init, dtype=tf.float32)\n",
    "vsi_initializer = vsi(factor=config.vsi_init, dtype=tf.float32)\n",
    "zero_initializer = tf.zeros_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feeder(config, word_array):\n",
    "    \"\"\"Generator. Yields training example tuples: (input, target).\n",
    "\n",
    "    Args:\n",
    "        config: Config object with model parameters.\n",
    "        word_array: np.array (int), as generated by docload.build_word_array()\n",
    "\n",
    "    Returns:\n",
    "        Yields a tuple of NumPy arrays: (input, target)\n",
    "    \"\"\"\n",
    "    batch_width = len(word_array) // config.batch_size\n",
    "    data = np.reshape(word_array[0 : config.batch_size*batch_width],\n",
    "                      (config.batch_size, batch_width))\n",
    "    shuffle_index = [x for x in range(batch_width - config.num_rnn_steps - 1)]\n",
    "    random.shuffle(shuffle_index)\n",
    "    for i in shuffle_index:\n",
    "        x = data[:, (i):(i+config.num_rnn_steps)]\n",
    "        y = data[:, (i+1):(i+config.num_rnn_steps+1)]\n",
    "        yield (x, y)\n",
    "        \n",
    "def epoch_len(config, word_array):\n",
    "    \"\"\"Number of training steps in an epoch. Used for progress bar\"\"\"\n",
    "    batch_width = len(word_array) // config.batch_size\n",
    "    return batch_width - config.num_rnn_steps - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(config):\n",
    "    '''Embedding layer and RNN'''\n",
    "\n",
    "    with tf.name_scope('embedding'):\n",
    "        x = tf.placeholder(tf.int32, shape=(config.batch_size, config.num_rnn_steps), name='input')\n",
    "        with tf.variable_scope('embedding', initializer=rui_initializer):\n",
    "            embed_w = tf.get_variable('w', [config.vocab_size, config.embed_size])\n",
    "        embed_out = tf.nn.embedding_lookup(embed_w, x, name='output')\n",
    "            \n",
    "#     with tf.name_scope('rnn'):    \n",
    "    with tf.variable_scope('rnn', initializer=vsi_initializer):\n",
    "        rnn_cell = tf.contrib.rnn.BasicLSTMCell(config.rnn_size, activation=tf.tanh)\n",
    "        rnn_out, state = tf.nn.dynamic_rnn(rnn_cell, embed_out, dtype=tf.float32)\n",
    "    \n",
    "    with tf.name_scope('hidden'):\n",
    "        rnn_last_output = rnn_out[:, config.num_rnn_steps-1, :]\n",
    "        with tf.variable_scope('hidden'):\n",
    "            hid_w = tf.get_variable('w', (config.rnn_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            hid_b = tf.get_variable('b', config.hidden_size, initializer=zero_initializer)\n",
    "        hid_out = tf.nn.tanh(tf.matmul(rnn_last_output, hid_w) + hid_b)\n",
    "            \n",
    "    return hid_out, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss(config, hid_out):\n",
    "    \"\"\"Loss Function: noise contrastive estimation on final output of RNN\"\"\"\n",
    "    with tf.name_scope('loss'):\n",
    "        y = tf.placeholder(tf.int32, shape=(config.batch_size, config.num_rnn_steps))\n",
    "        y_last = tf.reshape(y[:, config.num_rnn_steps-1], [config.batch_size, 1],\n",
    "                           name='target')\n",
    "        with tf.variable_scope('loss'):\n",
    "            w = tf.get_variable('w', (config.vocab_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            b = tf.get_variable('b', config.vocab_size, initializer=zero_initializer)\n",
    "\n",
    "        batch_loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(w, b, inputs=hid_out, labels=y_last,\n",
    "                           num_sampled=config.neg_samples,\n",
    "                           num_classes=config.vocab_size,\n",
    "                           num_true=1), name='batch_loss')\n",
    "    with tf.name_scope('predict'):\n",
    "        y_hat = tf.argmax(tf.matmul(hid_out, w, transpose_b=True) + b, axis=1)\n",
    "    \n",
    "    return y, batch_loss, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(config, batch_loss):\n",
    "    with tf.name_scope('optimize'):\n",
    "#         optimizer = tf.train.GradientDescentOptimizer(config.learn_rate)\n",
    "        optimizer = tf.train.MomentumOptimizer(config.learn_rate, config.momentum)\n",
    "        train_op = optimizer.minimize(batch_loss, name='minimize_op')\n",
    "    \n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training_monitor(batch_loss):\n",
    "    with tf.name_scope('train_monitor'):\n",
    "        with tf.variable_scope('train_monitor'):\n",
    "            iteration = tf.get_variable('iteration', [], initializer=tf.zeros_initializer())\n",
    "            total_loss = tf.get_variable('total_loss', [], initializer=tf.zeros_initializer())\n",
    "        iter_update = tf.assign_add(iteration, tf.convert_to_tensor(1, dtype=tf.float32))\n",
    "        loss_update = tf.assign_add(total_loss, batch_loss)\n",
    "        avg_loss = tf.divide(loss_update, iter_update)\n",
    "    \n",
    "    return avg_loss, iteration, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary(config, avg_loss):\n",
    "    with tf.name_scope('summary'):\n",
    "        loss_monitor = tf.summary.scalar('loss_monitor', avg_loss)\n",
    "    now = datetime.utcnow().strftime(\"%m%d%H%M\")\n",
    "    logdir = \"../tf_logs/run-{}/\".format(now)\n",
    "    summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "    \n",
    "    return summary_writer, loss_monitor   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyGraph(object):\n",
    "    def __init__(self, config):\n",
    "        self.hid_out, self.x = model(config)\n",
    "        self.y, self.batch_loss, self.y_hat = loss(config, self.hid_out)\n",
    "        self.train_op = train(config, self.batch_loss)\n",
    "        self.avg_loss, self.iteration, self.tot_loss = training_monitor(self.batch_loss)\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.summary_writer, self.loss_monitor = summary(config, self.avg_loss)\n",
    "        self.saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "18.9931\n",
      "\n",
      "12.1337\n",
      "\n",
      "9.67044\n",
      "\n",
      "8.36546\n",
      "\n",
      "7.53386\n",
      "\n",
      "6.94486\n",
      "\n",
      "6.5103\n",
      "\n",
      "6.16606\n",
      "\n",
      "5.88737\n",
      "\n",
      "5.65325\n",
      "\n",
      "5.45366\n",
      "\n",
      "5.28169\n",
      "\n",
      "5.12983\n",
      "\n",
      "4.99445\n",
      "\n",
      "4.87302\n",
      "\n",
      "4.76252\n",
      "\n",
      "4.66147\n",
      "\n",
      "4.56844\n",
      "\n",
      "4.48205\n",
      "\n",
      "4.40158\n",
      "\n",
      "4.32624\n",
      "\n",
      "4.25585\n",
      "\n",
      "4.18991\n",
      "\n",
      "4.12797\n",
      "\n",
      "4.06972\n",
      "\n",
      "4.01454\n",
      "\n",
      "3.96203\n",
      "\n",
      "3.91238\n",
      "\n",
      "3.86517\n",
      "\n",
      "3.82026\n",
      "\n",
      "3.77749\n",
      "\n",
      "3.73671\n",
      "\n",
      "3.69792\n",
      "\n",
      "3.66109\n",
      "\n",
      "3.62582\n",
      "\n",
      "3.59221\n",
      "\n",
      "3.56003\n",
      "\n",
      "3.52927\n",
      "\n",
      "3.49982\n",
      "\n",
      "3.47149\n",
      "\n",
      "3.44418\n",
      "\n",
      "3.41847\n",
      "\n",
      "3.39351\n",
      "\n",
      "3.36964\n",
      "\n",
      "3.34695\n",
      "\n",
      "3.32517\n",
      "\n",
      "3.30415\n",
      "\n",
      "3.28412\n",
      "\n",
      "3.26484\n",
      "\n",
      "3.24646\n",
      "\n",
      "3.22841\n",
      "\n",
      "3.21097\n",
      "\n",
      "3.19416\n",
      "\n",
      "3.17799\n",
      "\n",
      "3.16267\n",
      "\n",
      "3.14795\n",
      "\n",
      "3.1344\n",
      "\n",
      "3.12141\n",
      "\n",
      "3.10871\n",
      "\n",
      "3.09609\n",
      "\n",
      "3.08401\n",
      "\n",
      "3.07211\n",
      "\n",
      "3.06063\n",
      "\n",
      "3.04959\n",
      "\n",
      "3.03886\n",
      "\n",
      "3.02847\n",
      "\n",
      "3.01858\n",
      "\n",
      "3.00898\n",
      "\n",
      "2.99954\n",
      "\n",
      "2.9905\n",
      "\n",
      "2.98168\n",
      "\n",
      "2.97309\n",
      "\n",
      "2.9648\n",
      "\n",
      "2.95668\n",
      "\n",
      "2.94877\n",
      "\n",
      "2.941\n",
      "\n",
      "2.93345\n",
      "\n",
      "2.92621\n",
      "\n",
      "2.91919\n",
      "\n",
      "2.91216\n",
      "\n",
      "2.90525\n",
      "\n",
      "2.89849\n",
      "\n",
      "2.89181\n",
      "\n",
      "2.88536\n",
      "\n",
      "2.8791\n",
      "\n",
      "2.87301\n",
      "\n",
      "2.86693\n",
      "\n",
      "2.86092\n",
      "\n",
      "2.85517\n",
      "\n",
      "2.84955\n",
      "\n",
      "2.84404\n",
      "\n",
      "2.83862\n",
      "\n",
      "2.83325\n",
      "\n",
      "2.82786\n",
      "\n",
      "2.82264\n",
      "\n",
      "2.81756\n",
      "\n",
      "2.81251\n",
      "\n",
      "2.80777\n",
      "\n",
      "2.80305\n",
      "\n",
      "2.79838\n",
      "\n",
      "2.7936\n",
      "\n",
      "2.78894\n",
      "\n",
      "2.78454\n",
      "\n",
      "2.78017\n",
      "\n",
      "2.77591\n",
      "\n",
      "2.77164\n",
      "\n",
      "2.7674\n",
      "\n",
      "2.76332\n",
      "\n",
      "2.75925\n",
      "\n",
      "2.7553\n",
      "\n",
      "2.7513\n",
      "\n",
      "2.74736\n",
      "\n",
      "2.74346\n",
      "\n",
      "2.73977\n",
      "\n",
      "2.73617\n",
      "\n",
      "2.73259\n",
      "\n",
      "2.72904\n",
      "\n",
      "2.72552\n",
      "\n",
      "2.72209\n",
      "\n",
      "2.71866\n",
      "\n",
      "2.71526\n",
      "\n",
      "2.71186\n",
      "\n",
      "2.70852\n",
      "\n",
      "2.70528\n",
      "\n",
      "2.70203\n",
      "\n",
      "2.69878\n",
      "\n",
      "2.69559\n",
      "\n",
      "2.69241\n",
      "\n",
      "2.68929\n",
      "\n",
      "2.68615\n",
      "\n",
      "2.68307\n",
      "\n",
      "2.68024\n",
      "\n",
      "2.6774\n",
      "\n",
      "2.67458\n",
      "\n",
      "2.6718\n",
      "\n",
      "2.66896\n",
      "\n",
      "2.66621\n",
      "\n",
      "2.6635\n",
      "\n",
      "2.66071\n",
      "\n",
      "2.65799\n",
      "\n",
      "2.65527\n",
      "\n",
      "2.65256\n",
      "\n",
      "2.64987\n",
      "\n",
      "2.64719\n",
      "\n",
      "2.64463\n",
      "\n",
      "2.64212\n",
      "\n",
      "2.6396\n",
      "\n",
      "2.63704\n",
      "\n",
      "2.63457\n",
      "\n",
      "2.63205\n",
      "\n",
      "2.62966\n",
      "\n",
      "2.62736\n",
      "\n",
      "2.62503\n",
      "\n",
      "2.62266\n",
      "\n",
      "2.62033\n",
      "\n",
      "2.61809\n",
      "\n",
      "2.61593\n",
      "\n",
      "2.61373\n",
      "\n",
      "2.6115\n",
      "\n",
      "2.60933\n",
      "\n",
      "2.60717\n",
      "\n",
      "2.60504\n",
      "\n",
      "2.60295\n",
      "\n",
      "2.60087\n",
      "\n",
      "2.5988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1d6db36a8453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                 [_, l, i, summary_str] = sess.run([g.train_op, g.avg_loss,\n\u001b[1;32m     13\u001b[0m                                                    g.iteration, g.loss_monitor],\n\u001b[0;32m---> 14\u001b[0;31m                                                   feed_dict=feed)\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    g = MyGraph(config)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(g.init)\n",
    "        counter = 0\n",
    "        for e in range(config.epochs):\n",
    "            for t in tqdm_notebook(feeder(config, word_array),\n",
    "                                   total=epoch_len(config, word_array),\n",
    "                                  desc='Epoch #{}'.format(e+1)):\n",
    "                counter += 1\n",
    "                feed = {g.x: t[0], g.y: t[1]}\n",
    "                [_, l, i, summary_str] = sess.run([g.train_op, g.avg_loss,\n",
    "                                                   g.iteration, g.loss_monitor],\n",
    "                                                  feed_dict=feed)\n",
    "                if (i % 100) == 0:\n",
    "                    g.summary_writer.add_summary(summary_str, counter)\n",
    "                    sess.run(g.iteration, feed_dict={g.iteration: 0, g.tot_loss: 0})\n",
    "            print(l)\n",
    "        save_path = g.saver.save(sess, \"../tmp/my_model.ckpt\")\n",
    "        g.summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config.batch_size = 1\n",
    "\n",
    "start = 1400  # start position in document\n",
    "input = word_array[start:(start+config.num_rnn_steps)]\n",
    "with tf.Graph().as_default():\n",
    "    g = MyGraph(config)\n",
    "    with tf.Session() as sess:\n",
    "        g.saver.restore(sess, \"../tmp/my_model.ckpt\")\n",
    "        for i in range(100):\n",
    "            feed = {g.x: np.reshape(input[i:(i+config.num_rnn_steps)], (1, -1))}\n",
    "            [pred] = sess.run([g.y_hat], feed_dict=feed)\n",
    "            input = np.append(input, [pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reverse_dict = {v: k for k, v in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print predicted passage\n",
    "passage_predict = [x for x in map(lambda x: reverse_dict[x], input)]\n",
    "readable = ''\n",
    "for word in passage_predict:\n",
    "    if word == '\"':\n",
    "        readable += word\n",
    "    elif word in ['?', '!', '.', ',']:\n",
    "        readable += word + ' '\n",
    "    else: \n",
    "        readable += ' ' + word\n",
    "print(readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
