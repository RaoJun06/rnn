{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network Trained on Sherlock Holmes\n",
    "\n",
    "*Patrick Coady (pcoady@alum.mit.edu)*\n",
    "\n",
    "This notebook trains a Recurrent Neural Network (RNN) on 3 *Sherlock Holmes* books. We use words as the input to the RNN (as opposed to a sequence of characters) and predict the last word in a sequence. A sampled loss function is used to avoid evaluating an ~11,500-way (i.e. vocabulary size) softmax on each training example.\n",
    "\n",
    "This notebook takes full advantage of [TensorBoard](https://www.tensorflow.org/get_started/embedding_viz):\n",
    "- graph visualization\n",
    "- monitor training loss\n",
    "- visualize trajectory weights and biases during training\n",
    "- visualize activations during training\n",
    "- 3D visualization of learned word vectors\n",
    "\n",
    "Objectives:\n",
    "1. Learn and apply Tensorboard\n",
    "2. Subjectively evaluate the quality of RNN-learned word-embeddings\n",
    "3. Compare Basic RNN, GRU and LSTM cells\n",
    "4. Build a clean, compact TensorFlow model to help other learn TensorFlow and TensorBoard\n",
    "\n",
    "The results are are discussed in [this blog post](https://pat-coady.github.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tqdm import tqdm_notebook  # progress bar\n",
    "\n",
    "import docload  # convenient methods for loading and processing Project Gutenberg books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded and processed: 24080 lines, 247812 words.\n"
     ]
    }
   ],
   "source": [
    "# Load and process data\n",
    "files = ['../data/adventures_of_sherlock_holmes.txt',\n",
    "        '../data/hound_of_the_baskervilles.txt',\n",
    "        '../data/sign_of_the_four.txt']\n",
    "word_array, dictionary, num_lines, num_words = docload.build_word_array(\n",
    "    files, vocab_size=50000, gutenberg=True)\n",
    "reverse_dict = {v: k for k, v in dictionary.items()}\n",
    "print('Document loaded and processed: {} lines, {} words.'\n",
    "      .format(num_lines, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"Model parameters\"\"\"\n",
    "    def __init__(self, num_words):\n",
    "        self.vocab_size = num_words\n",
    "        self.batch_size = 32\n",
    "        self.rnn = 'lstm'        # rnn cell\n",
    "        self.num_rnn_steps = 10  # unrolled length of RNN\n",
    "        self.embed_size = 92     # input embedding\n",
    "        self.rnn_size = 128      # number of RNN units\n",
    "        self.hidden_size = 128   # hidden layer connected to last output of RNN\n",
    "        self.rui_init = 0.01     # maxval, -minval for random_uniform_initializer\n",
    "        self.vsi_init = 0.01     # stddev multiplier (factor) for variance_scaling_initializer\n",
    "        self.neg_samples = 64    # for noise contrastive estimation (candidate sampling loss function)\n",
    "        self.learn_rate = 0.1\n",
    "        self.opt = 'mom'         # optimizer\n",
    "        self.momentum = 0.9\n",
    "        self.epochs = 25\n",
    "        self.embed_vis_depth = 1024  # number of word embeddings to visualize in TensorBoard\n",
    "\n",
    "config = Config(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write metadata file for TensorBoard embedding visualization\n",
    "with open('../tf_logs/embed_metadata.tsv', 'w') as f:\n",
    "    for i in range(config.embed_vis_depth):\n",
    "        f.write(reverse_dict[i]+'\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# aliases for especially long TensorFlow calls\n",
    "rui = tf.random_uniform_initializer\n",
    "vsi = tf.contrib.layers.variance_scaling_initializer\n",
    "# commonly used initializers in model\n",
    "rui_initializer = rui(-config.rui_init, config.rui_init, dtype=tf.float32)\n",
    "vsi_initializer = vsi(factor=config.vsi_init, dtype=tf.float32)\n",
    "zero_initializer = tf.zeros_initializer(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def feeder(config, word_array):\n",
    "    \"\"\"Generator. Yields training example tuples: (input, target).\n",
    "\n",
    "    Args:\n",
    "        config: Config object with model parameters.\n",
    "        word_array: np.array (int), as generated by docload.build_word_array()\n",
    "\n",
    "    Returns:\n",
    "        Yields a tuple of NumPy arrays: (input, target)\n",
    "    \"\"\"\n",
    "    batch_width = len(word_array) // config.batch_size\n",
    "    data = np.reshape(word_array[0 : config.batch_size*batch_width],\n",
    "                      (config.batch_size, batch_width))\n",
    "    shuffle_index = [x for x in range(batch_width - config.num_rnn_steps - 1)]\n",
    "    random.shuffle(shuffle_index)\n",
    "    for i in shuffle_index:\n",
    "        x = data[:, (i):(i+config.num_rnn_steps)]\n",
    "        y = data[:, i+config.num_rnn_steps].reshape((-1, 1))\n",
    "        yield (x, y)\n",
    "        \n",
    "def epoch_len(config, word_array):\n",
    "    \"\"\"Number of training steps in an epoch. Used for progress bar\"\"\"\n",
    "    batch_width = len(word_array) // config.batch_size\n",
    "    return batch_width - config.num_rnn_steps - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(config):\n",
    "    '''Embedding layer, RNN and hidden layer'''\n",
    "    with tf.name_scope('embedding'):\n",
    "        x = tf.placeholder(tf.int32, shape=(config.batch_size, config.num_rnn_steps), name='input')\n",
    "        with tf.variable_scope('embedding', initializer=rui_initializer):\n",
    "            embed_w = tf.get_variable('w', [config.vocab_size, config.embed_size])\n",
    "        embed_out = tf.nn.embedding_lookup(embed_w, x, name='output')\n",
    "        tf.summary.histogram('embed_out', embed_out)        \n",
    "        top_embed = tf.Variable(tf.zeros([1024, config.embed_size], dtype=tf.float32),\n",
    "                                name=\"top_n_embedding\")\n",
    "        assign_embed = top_embed.assign(embed_w[:1024, :])\n",
    "            \n",
    "    with tf.variable_scope('rnn', initializer=vsi_initializer):\n",
    "        if config.rnn == 'lstm':\n",
    "            rnn_cell = tf.contrib.rnn.BasicLSTMCell(config.rnn_size, activation=tf.tanh)\n",
    "        rnn_out, state = tf.nn.dynamic_rnn(rnn_cell, embed_out, dtype=tf.float32)\n",
    "        tf.summary.histogram('rnn_out', rnn_out)        \n",
    "        \n",
    "    with tf.name_scope('hidden'):\n",
    "        rnn_last_output = rnn_out[:, config.num_rnn_steps-1, :]\n",
    "        with tf.variable_scope('hidden'):\n",
    "            hid_w = tf.get_variable('w', (config.rnn_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            hid_b = tf.get_variable('b', config.hidden_size, initializer=zero_initializer)\n",
    "        hid_out = tf.nn.tanh(tf.matmul(rnn_last_output, hid_w) + hid_b)\n",
    "        tf.summary.histogram('hid_out', hid_out)\n",
    "            \n",
    "    return hid_out, x, top_embed, assign_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loss(config, hid_out):\n",
    "    \"\"\"Loss Function: noise contrastive estimation on final output of RNN\"\"\"\n",
    "    with tf.name_scope('output'):\n",
    "        y = tf.placeholder(tf.int32, shape=(config.batch_size, 1))\n",
    "        with tf.variable_scope('output'):\n",
    "            w = tf.get_variable('w', (config.vocab_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            b = tf.get_variable('b', config.vocab_size, initializer=zero_initializer)\n",
    "        batch_loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(w, b, inputs=hid_out, labels=y,\n",
    "                           num_sampled=config.neg_samples,\n",
    "                           num_classes=config.vocab_size,\n",
    "                           num_true=1), name='batch_loss')\n",
    "        tf.summary.scalar('batch_loss', batch_loss)\n",
    "    \n",
    "    with tf.name_scope('predict'):\n",
    "        y_hat = tf.argmax(tf.matmul(hid_out, w, transpose_b=True) + b, axis=1)\n",
    "    \n",
    "    return y, batch_loss, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(config, batch_loss):\n",
    "    with tf.name_scope('optimize'):\n",
    "        step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        if config.opt == 'mom':\n",
    "            optimizer = tf.train.MomentumOptimizer(config.learn_rate, config.momentum)\n",
    "        train_op = optimizer.minimize(batch_loss, name='minimize_op', global_step=step)\n",
    "    \n",
    "    return train_op, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MyGraph(object):\n",
    "    def __init__(self, config):\n",
    "        self.hid_out, self.x, self.top_embed, self.assign_embed = model(config)\n",
    "        self.y, self.batch_loss, self.y_hat = loss(config, self.hid_out)\n",
    "        self.train_op, self.step = train(config, self.batch_loss)\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        # Save histogram of all trainable variables for viewing in TensorBoard\n",
    "        [tf.summary.histogram(v.name.replace(':', '_'), v) for v in tf.trainable_variables()]\n",
    "        self.summ = tf.summary.merge_all()\n",
    "        self.saver = tf.train.Saver(max_to_keep=2)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_vis(summary_writer, g):\n",
    "    \"\"\"Setup for Tensorboard embedding visualization\"\"\"\n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = g.top_embed.name\n",
    "    embedding.metadata_path = 'embed_metadata.tsv'\n",
    "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(summary_writer, config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_logfile_name(config):\n",
    "    \"\"\"Generate logfile name based on training configuration and model params\"\"\"\n",
    "    logfile_name = ('../tf_logs/{}_{}_st={}_es={}_rs={}_lr={}_e={}'.\n",
    "                    format(config.rnn, config.opt, config.num_rnn_steps, \n",
    "                           config.embed_size, config.rnn_size,\n",
    "                           config.learn_rate, config.epochs))\n",
    "    \n",
    "    return logfile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Loss (20 batch average): 6.734135413169861\n",
      "Epoch #2 Loss (20 batch average): 4.462639331817627\n",
      "Epoch #3 Loss (20 batch average): 4.534698891639709\n",
      "Epoch #4 Loss (20 batch average): 4.23189492225647\n",
      "Epoch #5 Loss (20 batch average): 3.8311721205711367\n",
      "Epoch #6 Loss (20 batch average): 4.089081299304962\n",
      "Epoch #7 Loss (20 batch average): 3.747584879398346\n",
      "Epoch #8 Loss (20 batch average): 3.8618975281715393\n",
      "Epoch #9 Loss (20 batch average): 3.6125536799430846\n",
      "Epoch #10 Loss (20 batch average): 3.453145980834961\n",
      "Epoch #11 Loss (20 batch average): 3.3830376863479614\n",
      "Epoch #12 Loss (20 batch average): 3.2474966168403627\n",
      "Epoch #13 Loss (20 batch average): 3.4024043440818788\n",
      "Epoch #14 Loss (20 batch average): 3.40530047416687\n",
      "Epoch #15 Loss (20 batch average): 3.370216965675354\n",
      "Epoch #16 Loss (20 batch average): 3.243196952342987\n",
      "Epoch #17 Loss (20 batch average): 3.0835397243499756\n",
      "Epoch #18 Loss (20 batch average): 3.1652146220207213\n",
      "Epoch #19 Loss (20 batch average): 3.121123969554901\n",
      "Epoch #20 Loss (20 batch average): 3.0252755641937257\n",
      "Epoch #21 Loss (20 batch average): 3.0990037322044373\n",
      "Epoch #22 Loss (20 batch average): 3.0575949907302857\n",
      "Epoch #23 Loss (20 batch average): 2.947180247306824\n",
      "Epoch #24 Loss (20 batch average): 2.913612496852875\n",
      "Epoch #25 Loss (20 batch average): 2.948850631713867\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "logfile_name = build_logfile_name(config)\n",
    "summary_interval = 250\n",
    "move_avg_len = 20\n",
    "move_avg_loss = np.zeros(move_avg_len)\n",
    "with tf.Graph().as_default():\n",
    "    g = MyGraph(config)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(g.init)\n",
    "        writer = tf.summary.FileWriter(logfile_name+'/', tf.get_default_graph())\n",
    "        for e in range(config.epochs):\n",
    "            for t in tqdm_notebook(feeder(config, word_array),\n",
    "                                   total=epoch_len(config, word_array),\n",
    "                                   desc='Epoch #{}'.format(e+1), leave=False):\n",
    "                feed = {g.x: t[0], g.y: t[1]}\n",
    "                [_, batch_loss, step] = sess.run([g.train_op, g.batch_loss, g.step],\n",
    "                                               feed_dict=feed)\n",
    "                move_avg_loss[step % move_avg_len] = batch_loss\n",
    "                if (step % summary_interval) == 0:\n",
    "                    sess.run(g.assign_embed)\n",
    "                    writer.add_summary(sess.run(g.summ, feed_dict=feed), step)\n",
    "            print('Epoch #{} Loss ({} batch average): {}'.\n",
    "                  format(e+1, move_avg_len, np.mean(move_avg_loss)))\n",
    "            last_saved = g.saver.save(sess, logfile_name, global_step=e)\n",
    "        embed_vis(writer, g)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "config.batch_size = 1\n",
    "pred_length = 200\n",
    "\n",
    "start = 11698  # start position in document\n",
    "input = word_array[start:(start+config.num_rnn_steps)]\n",
    "with tf.Graph().as_default():\n",
    "    g = MyGraph(config)\n",
    "    with tf.Session() as sess:\n",
    "        g.saver.restore(sess, last_saved)\n",
    "        for i in range(250):\n",
    "            feed = {g.x: np.reshape(input[i:(i+config.num_rnn_steps)], (1, -1))}\n",
    "            [pred] = sess.run([g.y_hat], feed_dict=feed)\n",
    "            input = np.append(input, [pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " how did you know, for example, that i should be happy to suggest my assistance.\"\" i am sure that i will confine myself upon my request, therefore, as i am sure. i am sure that i will confine my attentions to the presence of the late whom i could lay my wound at his hat, and he stopped, while he stamped his shoulders stretched out his shoulders from his features.\"\"\"\" i am sure that i will confine myself upon my request, therefore, as i am sure. i am sure that i will confine my attentions to the presence of the late whom i could lay my wound at his hat, and he stopped, while he stamped his shoulders stretched out his shoulders from his features.\"\"\"\" i am sure that i will confine myself upon my request, therefore, as i am sure. i am sure that i will confine my attentions to the presence of the late whom i could lay my wound at his hat, and he stopped, while he stamped his shoulders stretched out his shoulders from his features.\"\"\"\" i am sure that i will confine myself upon my request, therefore, as i am sure. i am sure that i will confine my attentions to the presence of the late whom i could lay my wound at his hat, and\n"
     ]
    }
   ],
   "source": [
    "# print predicted passage\n",
    "passage_predict = [x for x in map(lambda x: reverse_dict[x], input)]\n",
    "readable = ''\n",
    "for word in passage_predict:\n",
    "    if word in '()\"?!,.;:':\n",
    "        readable += word\n",
    "    else: \n",
    "        readable += ' ' + word\n",
    "print(readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "024d298fa3f94bac97b2a96543f7608c": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "082a049be4c4494bbf323244e5f57f47": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "10ee36053c054048a858588df3978a00": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "1996456736ab409facfcc6e38b3d0a37": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "19ab67c5b3434c05a6b49966c72bbd50": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "2468a168ec27408595a141f08adb1e21": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "28317841e682493c9ce49b75edf2a464": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "29b17386a759494faf179eabfcf235d8": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "2cc908b74cfa4f309fdb8b2772611265": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "2ff42265b50e4078a32b608cc356943e": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "335a70cf5c9d4d7c890a71198d67e4fb": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "36a5ce642f65429089b159fc39e873f5": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "42a58e93aa9f48be8a81fa132533906e": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "45953ef3923f42048db2ad42bc1210d5": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "46cc87dc2223447c9c5c11d60d6c0951": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "498ec22972704bc8ab7706dcf3047c8e": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "4a82495cf4e8479795529bd3aaab23a4": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "4bd87d690dd7448bb3492d4017d56399": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "4f6d9af5b8ab4b009ae06e18d886c475": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "50a6e232201145afbca17364964407f9": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "574c5035b82d4823ab91fa4266cc12e5": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "59bd38a20f1142bdac329d6c33cd5df8": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "5a19fc193dcf4184b9f6a8ac2c61e7bd": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "60a870eee59a41b3be60905d82a5ffa8": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "642277ab9e0849e2b0ba18c1f3745acd": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "64dd0abf658a4848b7d39864eb037832": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "6e6556eab034467399c8acf62379b24c": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "6ece6170596d48a784c2891a2545dd91": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "705c7173fa604044b23a14af64593cfa": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "75298f8b7323483ba19720360a630fe9": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "7d2f4865793446cab5bb918601af77a7": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "81108d44e3d74bde83261c8e36a2c120": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "84a919c35cac436ca88bff4d46e0e401": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "8bd9a181d2f048aebcb81dba31f05696": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "919f5ca5516f448b8907b21b261c6431": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "978885091adc437b93ef82cdedd8da07": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "99c56929b76a420b8ad25b0a4035f4b7": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "9f81d2e575d64dddafa9164f6d499e9b": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a0a2e2737bfb41a4a389e244bc2a27e1": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a2011c2382ae4e8e922944376fa89b02": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a79a2b9a12714dd9b7a14e2930f93912": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a914a7346d6747598d59581000cb7ebe": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "b0e4ac7c4eac498b81151c7d770c9503": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "bff60a80da9648ea9b820be3b1d430d4": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "c5d6a7f424684692a8d9a28a57d0257c": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "c8bc9169cea54a33be150297eabb2e13": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "cc3dd28fa7934fb69bf4c84c455053a2": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "d440daa19079456884966ec0f3ce4b83": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "e506c9e3023d417887a251657f700340": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "eba1f84e773e44e7b2136cf738dc1dc2": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "ec86e8a52eb04cbf9543d3eeb95c2ad0": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "eebc5e2589ee434fbd04cde9c2eac112": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "f18447647ca14ba6bdfcf82a890ec41a": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "f236de55404d4bbc8bde57fb37786734": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "f6b2319474fd430684544d08afde402b": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
