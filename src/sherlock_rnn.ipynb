{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Recurrent Neural Network Trained on Sherlock Holmes\n",
    "\n",
    "*Patrick Coady (pcoady@alum.mit.edu)*\n",
    "\n",
    "This notebook trains a Recurrent Neural Network (RNN) on 3 *Sherlock Holmes* books. We use words as the input to the RNN (as opposed to a sequence of characters) and predict the last word in a sequence. A sampled loss function is used to avoid evaluating an ~11,500-way (i.e. vocabulary size) softmax on each training example.\n",
    "\n",
    "This notebook takes full advantage of [TensorBoard](https://www.tensorflow.org/get_started/embedding_viz):\n",
    "- view graph connections\n",
    "- monitor training loss\n",
    "- visualize weight and bias trajectories\n",
    "- visualize activations during training\n",
    "- Interactively explore 3D word embedding (t-SNE or PCA)\n",
    "\n",
    "Objectives:\n",
    "1. Learn Tensorboard\n",
    "2. Subjectively evaluate the quality of RNN-learned word-embeddings\n",
    "3. Compare Basic RNN, GRU and LSTM cells\n",
    "4. Build good example to help others learn TensorFlow and TensorBoard\n",
    "\n",
    "The results are are discussed in [this blog post](https://pat-coady.github.io/projects/2017/03/09/rnn-and-tensorboard.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tqdm import tqdm_notebook  # progress bar\n",
    "\n",
    "import docload  # convenient methods for loading and processing Project Gutenberg books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded and processed: 24080 lines, 247812 words.\n"
     ]
    }
   ],
   "source": [
    "# Load and process data\n",
    "files = ['../data/adventures_of_sherlock_holmes.txt',\n",
    "        '../data/hound_of_the_baskervilles.txt',\n",
    "        '../data/sign_of_the_four.txt']\n",
    "word_array, dictionary, num_lines, num_words = docload.build_word_array(\n",
    "    files, vocab_size=50000, gutenberg=True)\n",
    "reverse_dict = {v: k for k, v in dictionary.items()}\n",
    "print('Document loaded and processed: {} lines, {} words.'\n",
    "      .format(num_lines, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters and training configuration\n",
    "class Config(object):\n",
    "    \"\"\"Model parameters\"\"\"\n",
    "    def __init__(self, num_words):\n",
    "        self.vocab_size = num_words\n",
    "        self.batch_size = 32\n",
    "        self.num_rnn_steps = 20  # unrolled length of RNN\n",
    "        self.embed_size = 64     # input embedding\n",
    "        self.rnn_size = 128      # number of RNN units\n",
    "        self.hidden_size = 196   # hidden layer connected to last output of RNN\n",
    "        self.rui_init = 0.01     # maxval, -minval for random_uniform_initializer\n",
    "        self.vsi_init = 0.01     # stddev multiplier (factor) for variance_scaling_initializer\n",
    "        self.neg_samples = 64    # for noise contrastive estimation (candidate sampling loss function)\n",
    "        self.learn_rate = 0.05\n",
    "        self.momentum = 0.8\n",
    "        self.epochs = 75\n",
    "        self.embed_vis_depth = 2048  # number of word embeddings to visualize in TensorBoard\n",
    "\n",
    "config = Config(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Aliases for especially long TensorFlow calls\n",
    "rui = tf.random_uniform_initializer\n",
    "vsi = tf.contrib.layers.variance_scaling_initializer\n",
    "# Commonly used weight and bias initializers\n",
    "rui_initializer = rui(-config.rui_init, config.rui_init, dtype=tf.float32)\n",
    "vsi_initializer = vsi(factor=config.vsi_init, dtype=tf.float32)\n",
    "zero_initializer = tf.zeros_initializer(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def feeder(config, word_array):\n",
    "    \"\"\"Generator. Yields training example tuples: (input, target).\n",
    "\n",
    "    Args:\n",
    "        config: Config object with model parameters.\n",
    "        word_array: np.array (int), as generated by docload.build_word_array()\n",
    "\n",
    "    Returns:\n",
    "        Yields a tuple of NumPy arrays: (input, target)\n",
    "    \"\"\"\n",
    "    batch_width = len(word_array) // config.batch_size\n",
    "    # reshape data for easy slicing into shape = (batch_size, num_rnn_steps)\n",
    "    data = np.reshape(word_array[0 : config.batch_size*batch_width],\n",
    "                      (config.batch_size, batch_width))\n",
    "    shuffle_index = [x for x in range(batch_width - config.num_rnn_steps - 1)]\n",
    "    random.shuffle(shuffle_index)\n",
    "    for i in shuffle_index:\n",
    "        x = data[:, (i):(i+config.num_rnn_steps)]\n",
    "        y = data[:, i+config.num_rnn_steps].reshape((-1, 1))\n",
    "        yield (x, y)\n",
    "        \n",
    "def epoch_len(config, word_array):\n",
    "    \"\"\"Number of training steps in an epoch. Used for progress bar\"\"\"\n",
    "    batch_width = len(word_array) // config.batch_size\n",
    "    return batch_width - config.num_rnn_steps - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(config):\n",
    "    '''Embedding layer, RNN and hidden layer'''\n",
    "    with tf.name_scope('embedding'):\n",
    "        x = tf.placeholder(tf.int32, shape=(config.batch_size, config.num_rnn_steps), name='input')\n",
    "        with tf.variable_scope('embedding', initializer=rui_initializer):\n",
    "            embed_w = tf.get_variable('w', [config.vocab_size, config.embed_size])\n",
    "        embed_out = tf.nn.embedding_lookup(embed_w, x, name='output')\n",
    "        tf.summary.histogram('embed_out', embed_out)  # for TensorBoard\n",
    "        # keep only top N=embed_vis_depth vectors for TensorBoard visualization:\n",
    "        top_embed = tf.Variable(tf.zeros([config.embed_vis_depth, config.embed_size],\n",
    "                                         dtype=tf.float32),\n",
    "                                name=\"top_n_embedding\")\n",
    "        assign_embed = top_embed.assign(embed_w[:config.embed_vis_depth, :])\n",
    "            \n",
    "    with tf.variable_scope('rnn', initializer=vsi_initializer):\n",
    "        rnn_cell = tf.contrib.rnn.BasicLSTMCell(config.rnn_size, activation=tf.tanh)\n",
    "        rnn_out, state = tf.nn.dynamic_rnn(rnn_cell, embed_out, dtype=tf.float32)\n",
    "        tf.summary.histogram('rnn_out', rnn_out)  # for TensorBoard   \n",
    "        \n",
    "    with tf.name_scope('hidden'):\n",
    "        rnn_last_output = rnn_out[:, config.num_rnn_steps-1, :]\n",
    "        with tf.variable_scope('hidden'):\n",
    "            hid_w = tf.get_variable('w', (config.rnn_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            hid_b = tf.get_variable('b', config.hidden_size, initializer=zero_initializer)\n",
    "        hid_out = tf.nn.tanh(tf.matmul(rnn_last_output, hid_w) + hid_b)\n",
    "        tf.summary.histogram('hid_out', hid_out)  # for TensorBoard\n",
    "            \n",
    "    return hid_out, x, top_embed, assign_embed, embed_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loss(config, hid_out):\n",
    "    \"\"\"Loss Function: noise contrastive estimation on final output of RNN\"\"\"\n",
    "    with tf.name_scope('output'):\n",
    "        y = tf.placeholder(tf.int32, shape=(config.batch_size, 1))\n",
    "        with tf.variable_scope('output'):\n",
    "            w = tf.get_variable('w', (config.vocab_size, config.hidden_size),\n",
    "                                   initializer=vsi_initializer)\n",
    "            b = tf.get_variable('b', config.vocab_size, initializer=zero_initializer)\n",
    "        batch_loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(w, b, inputs=hid_out, labels=y,\n",
    "                           num_sampled=config.neg_samples,\n",
    "                           num_classes=config.vocab_size,\n",
    "                           num_true=1), name='batch_loss')\n",
    "        tf.summary.scalar('batch_loss', batch_loss)\n",
    "        # keep only top N=embed_vis_depth vectors for TensorBoard visualization:\n",
    "        top_embed = tf.Variable(tf.zeros([config.embed_vis_depth, config.hidden_size],\n",
    "                                         dtype=tf.float32),\n",
    "                                name=\"top_n_embedding\")\n",
    "        assign_embed = top_embed.assign(w[:config.embed_vis_depth, :])\n",
    "    \n",
    "    with tf.name_scope('predict'):\n",
    "        y_hat = tf.argmax(tf.matmul(hid_out, w, transpose_b=True) + b, axis=1)\n",
    "    \n",
    "    return y, batch_loss, y_hat, top_embed, assign_embed, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(config, batch_loss):\n",
    "    with tf.name_scope('optimize'):\n",
    "        step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        optimizer = tf.train.MomentumOptimizer(config.learn_rate, config.momentum)\n",
    "        train_op = optimizer.minimize(batch_loss, name='minimize_op', global_step=step)\n",
    "    \n",
    "    return train_op, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MyGraph(object):\n",
    "    def __init__(self, config):\n",
    "        self.hid_out, self.x, self.top_embed_in, self.assign_embed_in, self.embed_w = model(config)\n",
    "        self.y, self.batch_loss, self.y_hat, self.top_embed_out, self.assign_embed_out, self.w = \\\n",
    "            loss(config, self.hid_out)\n",
    "        self.train_op, self.step = train(config, self.batch_loss)\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        # Save histogram of all trainable variables for viewing in TensorBoard\n",
    "        [tf.summary.histogram(v.name.replace(':', '_'), v) for v in tf.trainable_variables()]\n",
    "        self.summ = tf.summary.merge_all()\n",
    "        self.saver = tf.train.Saver(max_to_keep=2)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def embed_vis(summary_writer, g):\n",
    "    \"\"\"Setup for Tensorboard embedding visualization\"\"\"\n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    # input embedding\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = g.top_embed_in.name  \n",
    "    embedding.metadata_path = 'embed_metadata.tsv'\n",
    "    # output embedding\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = g.top_embed_out.name\n",
    "    embedding.metadata_path = 'embed_metadata.tsv'\n",
    "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(summary_writer, config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_logfile_name(config):\n",
    "    \"\"\"Generate logfile name based on training configuration and model params\"\"\"\n",
    "    logfile_name = ('../tf_logs/st={}_es={}_rs={}_lr={}_e={}'.\n",
    "                    format(config.num_rnn_steps, \n",
    "                           config.embed_size, config.rnn_size,\n",
    "                           config.learn_rate, config.epochs))\n",
    "    \n",
    "    return logfile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Loss (20 batch average): 4.9349730014801025\n",
      "Epoch #2 Loss (20 batch average): 4.272949707508087\n",
      "Epoch #3 Loss (20 batch average): 4.122169363498688\n",
      "Epoch #4 Loss (20 batch average): 3.879178357124329\n",
      "Epoch #5 Loss (20 batch average): 3.8330237865448\n",
      "Epoch #6 Loss (20 batch average): 3.6574907183647154\n",
      "Epoch #7 Loss (20 batch average): 3.6320635437965394\n",
      "Epoch #8 Loss (20 batch average): 3.531160998344421\n",
      "Epoch #9 Loss (20 batch average): 3.468689668178558\n",
      "Epoch #10 Loss (20 batch average): 3.431946647167206\n",
      "Epoch #11 Loss (20 batch average): 3.269740867614746\n",
      "Epoch #12 Loss (20 batch average): 3.336487865447998\n",
      "Epoch #13 Loss (20 batch average): 3.104219925403595\n",
      "Epoch #14 Loss (20 batch average): 3.130649220943451\n",
      "Epoch #15 Loss (20 batch average): 3.0503926396369936\n",
      "Epoch #16 Loss (20 batch average): 3.032705318927765\n",
      "Epoch #17 Loss (20 batch average): 3.0309717655181885\n",
      "Epoch #18 Loss (20 batch average): 2.895249330997467\n",
      "Epoch #19 Loss (20 batch average): 2.8629628658294677\n",
      "Epoch #20 Loss (20 batch average): 2.8621017694473267\n",
      "Epoch #21 Loss (20 batch average): 2.6731433987617494\n",
      "Epoch #22 Loss (20 batch average): 2.7187861442565917\n",
      "Epoch #23 Loss (20 batch average): 2.6010977029800415\n",
      "Epoch #24 Loss (20 batch average): 2.7089255452156067\n",
      "Epoch #25 Loss (20 batch average): 2.5046050429344175\n",
      "Epoch #26 Loss (20 batch average): 2.608962869644165\n",
      "Epoch #27 Loss (20 batch average): 2.6175330519676208\n",
      "Epoch #28 Loss (20 batch average): 2.462488031387329\n",
      "Epoch #29 Loss (20 batch average): 2.4624834418296815\n",
      "Epoch #30 Loss (20 batch average): 2.5377891063690186\n",
      "Epoch #31 Loss (20 batch average): 2.5163261532783507\n",
      "Epoch #32 Loss (20 batch average): 2.4702449321746824\n",
      "Epoch #33 Loss (20 batch average): 2.5030416369438173\n",
      "Epoch #34 Loss (20 batch average): 2.3063826620578767\n",
      "Epoch #35 Loss (20 batch average): 2.373473417758942\n",
      "Epoch #36 Loss (20 batch average): 2.309232312440872\n",
      "Epoch #37 Loss (20 batch average): 2.349017721414566\n",
      "Epoch #38 Loss (20 batch average): 2.444905662536621\n",
      "Epoch #39 Loss (20 batch average): 2.3025277853012085\n",
      "Epoch #40 Loss (20 batch average): 2.3094458043575288\n",
      "Epoch #41 Loss (20 batch average): 2.241609734296799\n",
      "Epoch #42 Loss (20 batch average): 2.1744826078414916\n",
      "Epoch #43 Loss (20 batch average): 2.255762588977814\n",
      "Epoch #44 Loss (20 batch average): 2.222712290287018\n",
      "Epoch #45 Loss (20 batch average): 2.1788590371608736\n",
      "Epoch #46 Loss (20 batch average): 2.18891926407814\n",
      "Epoch #47 Loss (20 batch average): 2.1517030715942385\n",
      "Epoch #48 Loss (20 batch average): 2.1875949144363402\n",
      "Epoch #49 Loss (20 batch average): 2.1137719213962556\n",
      "Epoch #50 Loss (20 batch average): 2.1127500414848326\n",
      "Epoch #51 Loss (20 batch average): 2.1443493187427523\n",
      "Epoch #52 Loss (20 batch average): 2.187007302045822\n",
      "Epoch #53 Loss (20 batch average): 2.142525202035904\n",
      "Epoch #54 Loss (20 batch average): 2.0365969240665436\n",
      "Epoch #55 Loss (20 batch average): 1.9719718098640442\n",
      "Epoch #56 Loss (20 batch average): 2.063862216472626\n",
      "Epoch #57 Loss (20 batch average): 2.086373966932297\n",
      "Epoch #58 Loss (20 batch average): 2.0708997905254365\n",
      "Epoch #59 Loss (20 batch average): 2.0883170306682586\n",
      "Epoch #60 Loss (20 batch average): 2.0225270807743074\n",
      "Epoch #61 Loss (20 batch average): 2.0903206765651703\n",
      "Epoch #62 Loss (20 batch average): 2.0867371022701264\n",
      "Epoch #63 Loss (20 batch average): 1.9661362588405609\n",
      "Epoch #64 Loss (20 batch average): 2.1600918412208556\n",
      "Epoch #65 Loss (20 batch average): 1.9196549892425536\n",
      "Epoch #66 Loss (20 batch average): 2.050838041305542\n",
      "Epoch #67 Loss (20 batch average): 2.082862150669098\n",
      "Epoch #68 Loss (20 batch average): 1.9878806471824646\n",
      "Epoch #69 Loss (20 batch average): 2.0405200719833374\n",
      "Epoch #70 Loss (20 batch average): 2.022554624080658\n",
      "Epoch #71 Loss (20 batch average): 1.9028755962848662\n",
      "Epoch #72 Loss (20 batch average): 1.9076278328895568\n",
      "Epoch #73 Loss (20 batch average): 1.9565611481666565\n",
      "Epoch #74 Loss (20 batch average): 1.9787074089050294\n",
      "Epoch #75 Loss (20 batch average): 2.0331187725067137\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "logfile_name = build_logfile_name(config)\n",
    "summary_interval = 250\n",
    "move_avg_len = 20  # number of batches to average loss over\n",
    "move_avg_loss = np.zeros(move_avg_len)\n",
    "with tf.Graph().as_default():\n",
    "    g = MyGraph(config)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(g.init)\n",
    "        writer = tf.summary.FileWriter(logfile_name+'/', tf.get_default_graph())\n",
    "        for e in range(config.epochs):\n",
    "            for t in tqdm_notebook(feeder(config, word_array),\n",
    "                                   total=epoch_len(config, word_array),\n",
    "                                   desc='Epoch #{}'.format(e+1), leave=False):\n",
    "                feed = {g.x: t[0], g.y: t[1]}\n",
    "                [_, batch_loss, step] = sess.run([g.train_op, g.batch_loss, g.step],\n",
    "                                               feed_dict=feed)\n",
    "                move_avg_loss[step % move_avg_len] = batch_loss\n",
    "                if (step % summary_interval) == 0:\n",
    "                    sess.run([g.assign_embed_in, g.assign_embed_out])\n",
    "                    writer.add_summary(sess.run(g.summ, feed_dict=feed), step)\n",
    "            print('Epoch #{} Loss ({} batch average): {}'.\n",
    "                  format(e+1, move_avg_len, np.mean(move_avg_loss)))\n",
    "            last_saved = g.saver.save(sess, logfile_name, global_step=e)\n",
    "        embed_vis(writer, g)\n",
    "        writer.close()\n",
    "        \n",
    "# Write metadata file for TensorBoard embedding visualization\n",
    "with open('../tf_logs/embed_metadata.tsv', 'w') as f:\n",
    "    for i in range(config.embed_vis_depth):\n",
    "        f.write(reverse_dict[i]+'\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict: seed with N=num_rnn_steps words -> predict next word -> update seed with prediction\n",
    "config.batch_size = 1\n",
    "start = 11000  # start position in document\n",
    "pred_length = 200\n",
    "input = word_array[start:(start+config.num_rnn_steps)]\n",
    "with tf.Graph().as_default():\n",
    "    g = MyGraph(config)\n",
    "    with tf.Session() as sess:\n",
    "        g.saver.restore(sess, last_saved)\n",
    "        for i in range(250):\n",
    "            feed = {g.x: np.reshape(input[i:(i+config.num_rnn_steps)], (1, -1))}\n",
    "            [pred] = sess.run([g.y_hat], feed_dict=feed)\n",
    "            input = np.append(input, [pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" you will remember that i remarked the other day, just before we went into the very simple problem and which has read their boots. all day that you have read from the paper and the convict - boat where he has not seen.\"\" it is,\" said holmes,\" that you have ever returned.\"\" i am sure that you are very much in the matter. i have brought you that there is a case between two or two else.\"\" i am sure that you are right,\" said he.\" i am afraid that you are right up before you come and look.\"\" by the way, that is possible, john,\" said he,\" that you have had a pretty clear chance. '\" 'i am sure when my wife died to me - -\"\" oh, indeed! i was glad that i could not get her hand.\" my dear mr. sherlock holmes, sir, that is my wife, and i find that mrs. laura lyons had left a seat which was moving beside him. quite weary and pale - pull. in the centre of the light of the lantern was open, and up i could see the low hill at the house, and then i saw then that night or two or two thoughts were still visible. at least my dear little, my dear watson, you are not\n"
     ]
    }
   ],
   "source": [
    "# Add crude formatting to make prediction readable\n",
    "passage_predict = [x for x in map(lambda x: reverse_dict[x], input)]\n",
    "readable = ''\n",
    "for word in passage_predict:\n",
    "    if word in '()\"?!,.;:':\n",
    "        readable += word\n",
    "    else: \n",
    "        readable += ' ' + word\n",
    "print(readable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "02bd45071c3b4018b173f8e31a6b12fc": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "0b868a98475a4070878b28b2c3a39257": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "0c287993114d4035b24738dd39f52358": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "10414e1cd784455daed065d8a815bbf4": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "169dfa1eca1442b8ad4c174e31ba9f20": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "171e5b5060cf472bbe9cb5b244db406c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "1885043e48464f768efa787d0d9c3add": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "1b967bc1fdee4d99afa939cce425ca57": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "1cbd3939b83b4379812be687f191ffca": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "1e54a1aaa0614e62ac798f0981182159": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "1e6d1ac9456d48078b85de7fba594e63": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "285105ea5ebc40f1b9c0666e466c4265": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "2c9ed36663374509b21e67cf784e3be8": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "2e551c91a96842f4b2492e35890078c1": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "3203c47cbdf241fdafb4d5dea493accf": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "3626382cef194186813ed9ac7f75db8d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "37b90a3206b5495bbc919303f821417c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "3fb24529cf3c4d1081b26e39db3af767": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "40106425c6ee4c7cbdcf597a5e80ee83": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "40bcc63454254651a74fa2874d7ff86a": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "429400ed74df416aaa94c57e534bf40d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "44c01bfead66410bb636bd78fa7de975": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "4b6c56d1702848d391caea9d8deb6c38": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "53798dbae6e944228fb52627d1ca7e94": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "5d142272f3ab496bb2bc791329052915": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "610652581e374fd8bd600afed3d566fe": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6328367d1ee4490e8b5fb308e7bed30c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "65af9c6fe23543b087e6696172cd522d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6719d247d07d4efcadd36fd911de232c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "674a47ae57c8419db1ed27cf5d83df6e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6846dfdf14ac49afbe3af4cb1037be07": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6cea86c492b54ee589723901ad7b276f": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6d68ed3dc324475a91ca2a80b8a67351": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6f762cbbd99243868895bfc60fdb126a": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6fb0a1d0a2f845449fc5c31b0045b72a": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "70453ee7bcdc466087091a14b26a0a2b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "7266696079694f34a647686afc79a5bb": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "76e91bea955544bd9a77736a8d8adf41": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "7758ebf886b642b69cab34e34fc253e8": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "820fbeab11144b6fb9b39450bade2bb8": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "874587a1b7e6458ca54cff544ecf25e9": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "8b9e4039a3c84f3796f48341fd65e761": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "8c153e4a23ab47d79916c1cb2a299f91": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "8c5049e519044e05a6012b42a276486c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "912363e3736a4a9fafd9806460e0c91b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "91515ac957814a8dba588dbb5e163a68": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "942558fb327a4e579e3a44dd861a444c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "94f2273d9a9f48aa916fbefe57653da0": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "98570d62da864e98a77bfb3af5d5ebb0": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "a0e0f2b92bb641daa7348827e042ac94": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "a58223c59894487384c788c492415449": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "accc3571c03b444998f2b87db10aba4c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "b046a6748aee47cebf3a82bccfa1a385": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "b0e079837661452e83156af50b29735f": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "b9e267386a0142e586dd8871a617be47": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "bddf2d1e1fdf4065b2522a1ff26b983b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "bf7ee50839664f2b8a94d1bde6243929": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "c175589edd36463abff5fa9f658e15ff": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "c365fbfaa19b4dcaa6f554295a3f441f": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "c560e7ad91a947018754d8c8cfe542b5": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "c9cff4f076854ac887d22a924ed4245f": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ca5a9655f5154d52987059bc20c5800c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "cc118420a3624eb9bf899c0bdcdeb875": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d2e59096cc664ecaa2a5f43bf4c28157": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d2f265f172a649538c22c2cfd1a08d38": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d840016995404e9eaaffc02ffbcef55e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d8e2ac53f54746a58a4b3ac43a3fd92e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "dabcab9a1b504558af53e803cae542e4": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "dd9a455b4224464fa55bbcc84fc8fb5e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e4dc78b5ecdc4570920cb714ac77d4ac": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e7d7e5360a7e445e98bf35ca0698a956": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ec01b799125d41fbb190f6e6dc6b5f0b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "f13adee0e9304b3299e2431583b432b3": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "f390269bc15e4678acbabf2de8196c3c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "fafdd0875db147ecbb6ee468de5be28a": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
